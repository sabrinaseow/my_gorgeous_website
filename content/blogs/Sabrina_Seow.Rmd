---
categories:
- ""
- ""
date: "2017-10-31T22:42:51-05:00"
description: Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna
  sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa
  sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem
  consequat tincidunt. Vivamus et sagittis tempus.
draft: false
image: pic07.jpg
keywords: ""
slug: sabrinaseow
title: Aliquam
---

```{r load-libraries, warning=FALSE, message=FALSE, echo=FALSE}
library(tidyverse)  # Load ggplot2, dplyr, and all the other tidyverse packages
library(gapminder)  # gapminder dataset
library(here)
library(janitor)
```

The goal is to test your software installation, to demonstrate competency in Markdown, and in the basics of `ggplot`.

# Task 1: Short biography written using markdown
## Hi, I'm **Sabrina Seow**
![A hot pic of me x](sabrina.jpg)

### About me
I'm a Malaysian and I graduated from The University of Manchester back in 2019 with a degree in Information Technology Management for Business. Post-graduation, I landed myself a job as an Associate Consultant in Ernst & Young Malaysia and I was there until just about a few months ago, where I quitted and decided to further my studies. Though my bachelors degree might sound very technical, I actually have only very little experience in coding. Hence, I look forward to upskilling myself and gain the technical capabilities I lack. 

**Random facts about me**:

* I speak four languages - *English*, *Mandarin*, *Cantonese* & *Malay*
* I am the youngest in the family. I have two older brothers 
* I used to not exercise at all but ever since I was introduced to indoor cycling, my lifestyle have changed completely
* I can't live without coffee 

**Let's connect!** - [LinkedIn](https://www.linkedin.com/in/sabrinaseow/)

# Task 2: `gapminder` country comparison

The `gapminder` dataset has data on life expectancy, population, and GDP per capita for 142 countries from 1952 to 2007. To get a glimpse of the dataframe, namely to see the variable names, variable types, etc., we use the `glimpse` function. We also want to have a look at the first 20 rows of data, which can be done using the `head` function. 

```{r}
glimpse(gapminder)
head(gapminder, 20) # look at the first 20 rows of the dataframe

```

### How life expectancy has changed over the years for the `country` and the `continent` I come from - `Malaysia` and `Asia`
```{r}
country_data <- gapminder %>% 
            filter(country == "Malaysia") 

continent_data <- gapminder %>% 
            filter(continent == "Asia")
```

Life expectancy over time for **Malaysia**
```{r, lifeExp_one_country}
plot1 <- ggplot(data = country_data, mapping = aes(x = year, y = lifeExp))+
  geom_point() +
  geom_smooth(se = FALSE)+
  NULL 

plot1
```

Adding an informative title to the plot using the `labs()` function
```{r, lifeExp_one_country_with_label}
plot1 <- plot1 +
  labs(title = "Life Expectancy of Malaysia's Population",
       x = "Year",
       y = "Life Expectancy") +
  NULL


plot1
```

Life expectancy over time for all countries in **Asia**
```{r lifeExp_one_continent}
ggplot(data = continent_data, mapping = aes(x = year, y = lifeExp, colour = country, group = country)) +
  geom_point() + 
  geom_smooth(se = FALSE) +
  NULL

```

### Life expectancy over time for all countries, grouped (or faceted) by continent
```{r lifeExp_facet_by_continent}
ggplot(data = gapminder , mapping = aes(x = year , y = lifeExp , colour = country))+
  geom_point() + 
  geom_smooth(se = FALSE) +
  facet_wrap(~continent) +
  theme(legend.position="none") + #remove all legends
  NULL
```

> **Analysis**

Based on the graph, we can see that the life expectancy across the globe has been increasing in general since 1952 except for a few countries, especially in the **Africa** continent. The increase in life expectancy over the years can be due to several factors, and I think the most significant one is due to medical advances over the years.

The life expectancy in a country is often linked to its' socioeconomic development, as developed countries have higher standards of living, more effective health systems, and more resources invested in determinants of health. In other words, the better the health and welfare of a country, the higher the life expectancy. 

**Africa** is home to nearly all of the world's poorest countries and I think that explains the differences in the patterns in the graph.

# Task 3: Brexit vote analysis

We will have a look at the results of the 2016 Brexit vote in the UK. First we read the data using `read_csv()` and have a quick `glimpse` at the data

```{r load_brexit_data, warning=FALSE, message=FALSE}
brexit_results <- read_csv(here::here("data","brexit_results.csv"))

glimpse(brexit_results)
```

Our main outcome variable (or y) is `leave_share`, which is the percent of votes cast in favour of Brexit, or leaving the EU. Each row is a UK [parliament constituency](https://en.wikipedia.org/wiki/United_Kingdom_Parliament_constituencies).

To get a sense of the spread, or distribution, of the data, we can plot a histogram, a density plot, and the empirical cumulative distribution function of the leave % in all constituencies.

```{r brexit_histogram, warning=FALSE, message=FALSE}

# histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_histogram(binwidth = 2.5) + 
  labs(title = "Histogram of Constituency Leave Votes",
       subtitle = "Vote spread uneven across constituencies",
       x = "Leave votes in constituency (%)",
       y = "Number of constituencies")

# density plot-- think smoothed histogram
ggplot(brexit_results, aes(x = leave_share)) +
  geom_density() +
  labs(title = "Density Plot of Constituency Leave Votes",
       subtitle = "The peak is just over 55%", 
       x = "Leave votes in constituency (%)", 
       y = "Density")

# The empirical cumulative distribution function (ECDF) 
ggplot(brexit_results, aes(x = leave_share)) +
  stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent) +
  labs(title = "ECDF Plot of Constituency Leave Votes",
       subtitle = "About 37% of constituencies had less than 50% leave votes",
       x = "Leave votes in constituency (%)",
       y = "% of constituencies")


```

One common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy. We can check the relationship (or correlation) between the proportion of native born residents (`born_in_uk`) in a constituency and its `leave_share` by getting the correlation between the two variables

```{r brexit_immigration_correlation}
brexit_results %>% 
  select(leave_share, born_in_uk) %>% 
  cor()
```

The correlation is almost 0.5, which shows that the two variables are positively correlated.

We can also create a scatterplot between these two variables using `geom_point`. 

```{r brexit_immigration_plot}
ggplot(brexit_results, aes(x = born_in_uk, y = leave_share)) +
  geom_point(alpha=0.3) +
  
  # add a smoothing line, and use method="lm" to get the best straight-line
  geom_smooth(method = "lm") + 
  
  # use a white background and frame the plot with a black box
  theme_bw() +
  
  # add an informative title, subtitle, and axes titles
  labs(title = "Brexit leave votes vs native born residents",
       subtitle = "Leave votes higher in areas with low immigration",
       x = "% of UK-born residents",
       y = "% of leave votes") +
  
  NULL
```

> **Analysis**

There is a positive relationship between the proportion of native born residents in a constituency and its percentage of votes cast leaving the EU. The higher the proportion of native born residents in a constituency, the higher its percentage of votes cast leaving the EU. 

This is in line with what has been mentioned above - *one common explanation for the Brexit outcome was fear of immigration and opposition to the EU's more open border policy*. Areas with high UK-born populations are usually in the suburbs, which as opposed to urban areas, houses more economically disadvantaged and low skilled communities. I believe these groups were the most likely to support Brexit as they are naturally worried about competition for jobs due to immigration. 

Not to say that people in urban areas don't fear competition for jobs, but I think what causes this divide in attitude towards immigration is their education levels. I think people who are highly-educated believes and knows that a more open border policy will further expand the economy and create much more job opportunities instead. 

# Task 4: Animal rescue incidents attended by the London Fire Brigade

Let's have a look at the [dataset on animal rescue incidents attended by the London Fire Brigade](https://data.london.gov.uk/dataset/animal-rescue-incidents-attended-by-lfb). First we read the data using `read_csv()` and have a quick `glimpse` at the data

```{r load_animal_rescue_data, warning=FALSE, message=FALSE}

url <- "https://data.london.gov.uk/download/animal-rescue-incidents-attended-by-lfb/8a7d91c2-9aec-4bde-937a-3998f4717cd8/Animal%20Rescue%20incidents%20attended%20by%20LFB%20from%20Jan%202009.csv"

animal_rescue <- read_csv(url,
                          locale = locale(encoding = "CP1252")) %>% 
  janitor::clean_names()


glimpse(animal_rescue)
```

Number of incidents by **year**, using `group_by()... summarise()` or, simply [`count()`](https://dplyr.tidyverse.org/reference/count.html)
```{r, instances_by_calendar_year}

animal_rescue %>% 
  dplyr::group_by(cal_year) %>% 
  summarise(count=n())

animal_rescue %>% 
  count(cal_year, name="count")

```

Number of incidents by **animal group**
```{r, animal_group_percentages}
animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  
  #group_by and summarise will produce a new column with the count in each animal group
  summarise(count = n()) %>% 
  
  # mutate adds a new column; here we calculate the percentage
  mutate(percent = round(100*count/sum(count),2)) %>% 
  
  # arrange() sorts the data by percent. Since the default sorting is min to max and we would like to see it sorted
  # in descending order (max to min), we use arrange(desc()) 
  arrange(desc(percent))


animal_rescue %>% 
  
  # count does the same thing as group_by and summarise
  # name = "count" will call the column with the counts "count" (exciting, I know)
  # and 'sort=TRUE' will sort them from max to min
  count(animal_group_parent, name="count", sort=TRUE) %>% 
  mutate(percent = round(100*count/sum(count),2))


```

> **Do you see anything strange in these tables?** 
> *There are two cat animal group - "Cat" and "cat", which should be combined into one.*

Finally, let us have a loot at the notional cost for rescuing each of these animals. As the LFB says,

*Please note that any cost included is a notional cost calculated based on the length of time rounded up to the nearest hour spent by Pump, Aerial and FRU appliances at the incident and charged at the current Brigade hourly rate.*

There is two things we will do:

1. Calculate the mean and median `incident_notional_cost` for each `animal_group_parent`
1. Plot a boxplot to get a feel for the distribution of `incident_notional_cost` by `animal_group_parent`.

Before we go on, however, we need to fix `incident_notional_cost` as it is stored as a `chr`, or character, rather than a number.

```{r, parse_incident_cost,message=FALSE, warning=FALSE}

# what type is variable incident_notional_cost from dataframe `animal_rescue`
typeof(animal_rescue$incident_notional_cost)

# readr::parse_number() will convert any numerical values stored as characters into numbers
animal_rescue <- animal_rescue %>% 

  # we use mutate() to use the parse_number() function and overwrite the same variable
  mutate(incident_notional_cost = parse_number(incident_notional_cost))

# incident_notional_cost from dataframe `animal_rescue` is now 'double' or numeric
typeof(animal_rescue$incident_notional_cost)

```

Now that `incident_notional_cost` is numeric, let us quickly calculate summary statistics for each animal group. 
```{r, stats_on_incident_cost,message=FALSE, warning=FALSE}

animal_rescue %>% 
  
  # group by animal_group_parent
  group_by(animal_group_parent) %>% 
  
  # filter resulting data, so each group has at least 6 observations
  filter(n()>6) %>% 
  
  # summarise() will collapse all values into 3 values: the mean, median, and count  
  # we use na.rm=TRUE to make sure we remove any NAs, or cases where we do not have the incident cos
  summarise(mean_incident_cost = mean (incident_notional_cost, na.rm=TRUE),
            median_incident_cost = median (incident_notional_cost, na.rm=TRUE),
            sd_incident_cost = sd (incident_notional_cost, na.rm=TRUE),
            min_incident_cost = min (incident_notional_cost, na.rm=TRUE),
            max_incident_cost = max (incident_notional_cost, na.rm=TRUE),
            count = n()) %>% 
  
  # sort the resulting data in descending order. You choose whether to sort by count or mean cost.
  arrange(desc(mean_incident_cost))

```

> **Compare the mean and the median for each animal group. what do you think this is telling us?
Anything else that stands out? Any outliers?**
> *By looking at the table, we can see that the mean is always larger than the median except for animals like Squirrel, Ferret and Rabbit. This means that some rescues for each animal cost much more than the average.*

Finally, let us plot a few plots that show the distribution of `incident_cost` for each animal group.

```{r, plots_on_incident_cost_by_animal_group,message=FALSE, warning=FALSE}

# base_plot
base_plot <- animal_rescue %>% 
  group_by(animal_group_parent) %>% 
  filter(n()>6) %>% 
  ggplot(aes(x=incident_notional_cost))+
  facet_wrap(~animal_group_parent, scales = "free")+
  theme_bw()

base_plot + geom_histogram()
base_plot + geom_density()
base_plot + geom_boxplot()
base_plot + stat_ecdf(geom = "step", pad = FALSE) +
  scale_y_continuous(labels = scales::percent)
```

> **Analysis**

I think the **boxplot** best communicates the variability of the data because it gives us a good indication of how the values are spread out. My analysis shows that the average cost of rescuing a Horse is more expensive compared to other animals, maybe because of the size of it as the average cost of rescuing a Cow is also relatively higher. 

However, the spread of values in the cost of rescuing each type of animals do show that it also depends on the incident itself. In fact, among all incidents, the most costly one was to rescue a **Cat**. 

